{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:28:47.767437Z","iopub.status.busy":"2024-06-17T04:28:47.766791Z","iopub.status.idle":"2024-06-17T04:29:27.967343Z","shell.execute_reply":"2024-06-17T04:29:27.966395Z","shell.execute_reply.started":"2024-06-17T04:28:47.767405Z"},"trusted":true},"outputs":[],"source":["!pip install peft\n","!pip install modelscope"]},{"cell_type":"markdown","metadata":{},"source":["## 【数据处理】"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:03.911282Z","iopub.status.busy":"2024-06-17T04:33:03.910565Z","iopub.status.idle":"2024-06-17T04:33:24.181989Z","shell.execute_reply":"2024-06-17T04:33:24.181054Z","shell.execute_reply.started":"2024-06-17T04:33:03.911252Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-18 19:56:29,975 - modelscope - INFO - PyTorch version 2.2.1 Found.\n","2024-06-18 19:56:29,983 - modelscope - INFO - Loading ast index from C:\\Users\\xingling\\.cache\\modelscope\\ast_indexer\n","2024-06-18 19:56:30,791 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 bf1f8c6a033ab849ecc796d2c086e805 and a total number of 980 components indexed\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n","You can remove this warning by passing 'verification_mode=no_checks' instead.\n","  warnings.warn(\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:926: FutureWarning: The repository for HC3-Chinese contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at C:\\Users\\xingling\\.cache\\modelscope\\hub\\datasets\\simpleai\\HC3-Chinese\\master\\meta\\HC3-Chinese.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["【数据集下载完成】\n"]}],"source":["import modelscope\n","from modelscope.msdatasets import MsDataset\n","#【下载数据集】\n","HC3=MsDataset.load('simpleai/HC3-Chinese', subset_name='baike', split='train') #调用HC3数据集\n","dataset=HC3.to_hf_dataset() #将MsDataset转换成huggingface dataset格式，方便后续处理\n","print(\"【数据集下载完成】\")"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:34.585363Z","iopub.status.busy":"2024-06-17T04:33:34.584724Z","iopub.status.idle":"2024-06-17T04:33:35.083295Z","shell.execute_reply":"2024-06-17T04:33:35.082379Z","shell.execute_reply.started":"2024-06-17T04:33:34.585330Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["硬盘安装就是从硬盘安装XP的系统，可以是一般的系统也可以是GHOST的。适用于没有或者光驱损坏的个人电脑用户。 \\n首先要到网上去下一个系统，解压后把文件名字修改为xp（便于在DOS下查找） \\n1、GHOST系统时候，重启进入DOS状态下，用UBDOC（超普DOS）或者是矮人DOS（这两个软件必须先下载安装，我用超普DOS），还有就是从光盘进入DOS，假设我们的系统安装程序放在D盘了， \\nc:\\_输入d:\\回车，显示D：\\_然后输入smartdrv再次输入smartdrv后回车（加载磁盘加速程序），然后输入CD XP回车，显示D：\\XP\\_然后输入GHOST回车，进入GHOST，在里面用鼠标如果没有加载就用键盘选择，找到from image然后回车一直回车，知道选择yes和no，选择yes，很快就装好了，大约10分，立刻重启。\n","松管光缆是一种将光纤装在一个或分装在多个管子里的光缆。 \\n在缆芯中不填充油膏的松管光缆。在这种光缆中用一种泡沫状的热塑性弹性体来代替传统松管光缆中的油膏,起到阻水的作用。这种光缆可以减小尺寸而保持机械性能或者保持尺寸而提高机械性能。取消油膏大大方便光缆端头的制备和光缆的接续,并有利于环境保护。这种光缆是由瑞典爱立信网络技术公司开发的,试制了架空、管道和直埋用光缆,报道了这些光缆的结构和性能试验结果。\n","硬盘安装是指将软件或操作系统安装到硬盘上的过程。硬盘是电脑的主存储器，通常使用硬盘来安装操作系统和其他软件。在安装硬盘之前，你需要准备好安装介质（通常是光盘或 USB 闪存盘），并按照操作系统的安装向导进行操作。安装完成后，你就可以使用硬盘上的软件了。\n","松管光缆是一种类型的光纤通信线路，它是由一个或多个光纤管构成，内部包含一条或多条光纤。松管光缆通常用于在难以进行铺设的地区进行长距离传输，例如河流、高速公路、隧道等。松管光缆的优点是可以提高线路的可靠性和安全性，并且可以提高传输速率。\n"]}],"source":["from datasets import Dataset\n","import numpy as np\n","import torch\n","import json\n","import pickle\n","\n","def dodo(ds,label):\n","    dataset=ds\n","    # dataset=np.array(ds)\n","    # print(dataset.shape)\n","    #数据集划分 train:val=8:2\n","    tot=len(dataset)\n","    n_train=int(tot*0.8)\n","    n_valid=tot-n_train\n","    \n","    # data_train=np.array(data_train)\n","    # data_valid=np.array(data_valid)\n","    # print(data_valid)\n","    # print(\"【data_train_{}】\".format(label),data_train.shape)\n","    # print(\"【data_valid_{}】\".format(label),data_valid.shape)\n","    \n","    path=\"./HC3/train.{}\".format(label)\n","    file=open(path, 'w',encoding='utf-8')\n","    print(ds[0].replace('\\n', '\\\\n'))\n","    for i in range(n_train):\n","        file.write(ds[i].replace('\\n', '\\\\n'))\n","        file.write('\\n')\n","\n","    path=\"./HC3/valid.{}\".format(label)\n","    file=open(path, 'w',encoding='utf-8')\n","    print(ds[n_train].replace('\\n', '\\\\n'))\n","    for i in range(n_valid):\n","        file.write(ds[n_train+i].replace('\\n', '\\\\n'))\n","        file.write('\\n')\n","\n","#【调整数据集格式】\n","ds0,ds1=[],[]\n","cnt=dataset.num_rows\n","for i in range(cnt):\n","    example=dataset[i]\n","    ds0.append(example[\"human_answers\"][0])\n","    ds1.append(example[\"chatgpt_answers\"][0])\n","\n","dodo(ds0,\"0\")\n","dodo(ds1,\"1\")"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'encode' is an invalid keyword argument for open()","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 读取文件\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./HC3/valid.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      6\u001b[0m     loaded_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_data)  \u001b[38;5;66;03m# 输出: {1: 'a', 2: 'b', 3: 'c'}\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","\u001b[1;31mTypeError\u001b[0m: 'encode' is an invalid keyword argument for open()"]}],"source":["import pickle\n"," \n","\n","# 读取文件\n","with open('./HC3/valid.1', 'rb',encode='utf-8') as file:\n","    loaded_data = pickle.load(file)\n"," \n","print(loaded_data)  # 输出: {1: 'a', 2: 'b', 3: 'c'}"]},{"cell_type":"markdown","metadata":{},"source":["## 【模型】"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:38.397691Z","iopub.status.busy":"2024-06-17T04:33:38.397054Z","iopub.status.idle":"2024-06-17T04:33:55.072749Z","shell.execute_reply":"2024-06-17T04:33:55.071859Z","shell.execute_reply.started":"2024-06-17T04:33:38.397659Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-17 04:33:40.508356: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-17 04:33:40.508488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-17 04:33:40.630987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9bb136cc1954e5db55456ead79c6a72","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8c3ca07dec342b8b78c205bfda30a2c","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37f5fd067c4c40d2b642c6b0322caf4b","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3deb0d591ce4d908007270c3c854fe9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Qwen2TokenizerFast(name_or_path='Qwen/Qwen1.5-0.5B', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03a6ab6ea4574eaeb2013890c58a7275","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc019884950f405dbbe6898a8247cb35","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["【token_train[0]】 {'label': 0, 'text': '网络节点是指一台电脑或其他设备与一个有独立地址和具有传送或接收数据功能的网络相连。节点可以是工作站、客户、网络用户或个人计算机，还可以是服务器、打印机和其他网络连接的设备。每一个工作站﹑服务器、终端设备、网络设备，即拥有自己唯一网络地址的设备都是网络节点。整个网络就是由这许许多多的网络节点组成的，把许多的网络节点用通信线路连接起来，形成一定的几何关系，这就是计算机网络拓扑。', 'input_ids': [71356, 92374, 104442, 106621, 104145, 105994, 101044, 57218, 46944, 18830, 102024, 46477, 33108, 100629, 112523, 57191, 106585, 20074, 98380, 9370, 71356, 111060, 1773, 92374, 73670, 20412, 114896, 5373, 100017, 5373, 71356, 20002, 57191, 99605, 104564, 3837, 104468, 20412, 89047, 5373, 117648, 105504, 71356, 64064, 9370, 101044, 1773, 104367, 114896, 123930, 239, 89047, 5373, 104992, 101044, 5373, 71356, 101044, 3837, 91676, 103926, 99283, 102157, 71356, 46477, 9370, 101044, 100132, 71356, 92374, 1773, 101908, 71356, 99486, 67071, 43288, 99454, 100694, 42140, 9370, 71356, 92374, 107339, 3837, 99360, 100694, 9370, 71356, 92374, 11622, 104516, 104634, 64064, 99793, 3837, 101894, 102495, 111867, 100145, 3837, 104301, 104564, 71356, 100786, 102498, 1773, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"]}],"source":["from transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer,DataCollatorWithPadding\n","\n","#【加载分词器】\n","tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\") #(\"bert-base-cased\")\n","tokenizer.pad_token_id = tokenizer.eos_token_id #Qwen特性，需要指定一下pad_token_id\n","print(tokenizer)\n","# print(\"【pad_token_id】\",tokenizer.pad_token_id)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"],padding=\"max_length\",truncation=True,max_length=512)\n","\n","token_train=data_train.map(tokenize_function, batched=True)\n","token_val=data_val.map(tokenize_function, batched=True)\n","print(\"【token_train[0]】\",token_train[0])\n","\n","train_dataset = token_train\n","eval_dataset = token_val"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#使用BERT模型\n","# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=5)\n","# print(model)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:58.480750Z","iopub.status.busy":"2024-06-17T04:33:58.480388Z","iopub.status.idle":"2024-06-17T04:34:04.025769Z","shell.execute_reply":"2024-06-17T04:34:04.024840Z","shell.execute_reply.started":"2024-06-17T04:33:58.480722Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb10cf5b2a1e4beea1ca0c1b47dcdc85","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7e298cebe41493ca0b9fabece58c4e9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["【model】\n"," Qwen2ForSequenceClassification(\n","  (model): Qwen2Model(\n","    (embed_tokens): Embedding(151936, 1024)\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (score): Linear(in_features=1024, out_features=2, bias=False)\n",")\n","【model.config】\n"," Qwen2Config {\n","  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"human\",\n","    \"1\": \"chatgpt\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 2816,\n","  \"label2id\": {\n","    \"chatgpt\": 1,\n","    \"human\": 0\n","  },\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"pad_token_id\": 151643,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"use_cache\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","【model.config.pad_token_id】 151643\n"]}],"source":["#【加载模型】\n","id2label = {0: \"human\", 1: \"chatgpt\"}\n","label2id = {\"human\": 0, \"chatgpt\": 1}\n","#使用Qwen1.5模型\n","model = AutoModelForSequenceClassification.from_pretrained(\"Qwen/Qwen1.5-0.5B\",num_labels=2,id2label=id2label,label2id=label2id)\n","model.config.pad_token_id=model.config.eos_token_id #这里也要指定一下pad_token_id，不然训练时会报错 \"ValueError: Cannot handle batch sizes > 1 if no padding token is defined.\"\n","print(\"【model】\\n\",model)\n","print(\"【model.config】\\n\",model.config)\n","print(\"【model.config.pad_token_id】\",model.config.pad_token_id)"]},{"cell_type":"markdown","metadata":{},"source":["## 【训练】"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:36:59.615974Z","iopub.status.busy":"2024-06-17T04:36:59.615082Z","iopub.status.idle":"2024-06-17T04:37:00.187197Z","shell.execute_reply":"2024-06-17T04:37:00.186366Z","shell.execute_reply.started":"2024-06-17T04:36:59.615928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/tmp/ipykernel_34/3640500368.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric=load_metric('accuracy') #评估指标\n","/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8921a053627c48408b6c423b05c9ee0a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#【训练参数】\n","from datasets import load_metric\n","import numpy as np\n","\n","training_args = TrainingArguments(\n","    output_dir=\"pt_save_pretrained\",\n","    evaluation_strategy=\"epoch\", #每跑完一个epoch输出一下测试信息\n","    num_train_epochs=2,\n","    per_device_train_batch_size=4, # 一共要跑 len(dataset)/batch_size * epoch 个step\n","                                  # [模型=Qwen1.5-0.5B, batch_size=4]：完全微调显存13.3GB，LoRA微调显存8.7GB\n","#     gradient_accumulation_steps=2,\n","    #     load_best_model_at_end=True,\n","    save_strategy=\"no\",  #关闭自动保存模型（Kaggle上磁盘空间不太够）\n","#     save_total_limit=1, #保存检查点数量的限制\n",")\n","\n","metric=load_metric('accuracy') #评估指标\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","def get_trainer(model): \n","    return  Trainer( \n","        model=model, \n","        args=training_args, \n","        tokenizer=tokenizer,\n","        train_dataset=train_dataset, \n","        eval_dataset=eval_dataset, \n","        compute_metrics=compute_metrics,\n","        data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\"), #给数据添加padding弄成batch\n","    ) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#【完全微调】\n","print(\"【开始训练】\")\n","trainer=get_trainer(model)\n","trainer.train()\n","\n","tokenizer.save_pretrained(\"./full_model_tokenizer\") \n","model.save_pretrained(\"./full_model\")\n","\n","#Kaggle注意：\n","#每次训练之后restart以释放显存！\n","#factory也reset一下，不然磁盘空间会爆！"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:37:06.150074Z","iopub.status.busy":"2024-06-17T04:37:06.149373Z","iopub.status.idle":"2024-06-17T05:01:11.990221Z","shell.execute_reply":"2024-06-17T05:01:11.989119Z","shell.execute_reply.started":"2024-06-17T04:37:06.150041Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PEFT参数量：\n","trainable params: 1,181,696 || all params: 465,171,456 || trainable%: 0.2540\n","【开始训练】\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240617_043743-e2nrmyuv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">pt_save_pretrained</a></strong> to <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">https://wandb.ai/chenxingling/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 23:08, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.102500</td>\n","      <td>0.113912</td>\n","      <td>0.986000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.052600</td>\n","      <td>0.107569</td>\n","      <td>0.986000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["#【PEFT-LoRA微调】\n","from peft import LoraConfig, get_peft_model\n","\n","peft_config = LoraConfig(\n","    task_type=\"SEQ_CLS\", #任务类型：分类 \n","    target_modules=[\"q_proh\",\"k_proj\",\"v_proj\",\"o_proj\"],  # 这个不同的模型需要设置不同的参数，主要看模型中的attention层\n","    inference_mode=False, # 关闭推理模式 (即开启训练模式)\n","    r=8, # Lora 秩\n","    lora_alpha=16, # Lora alaph，具体作用参见 Lora 原理\n","    lora_dropout=0.1 # Dropout 比例\n",")\n","\n","peft_model = get_peft_model(model, peft_config) # 加载lora参数peft框架\n","\n","print('PEFT参数量：') \n","peft_model.print_trainable_parameters() \n","\n","print(\"【开始训练】\")\n","peft_trainer=get_trainer(peft_model)\n","peft_trainer.train()\n","\n","tokenizer.save_pretrained(\"./peft_model_tokenizer\") \n","peft_model.save_pretrained(\"./peft_model\")"]},{"cell_type":"markdown","metadata":{},"source":["## 【测试】"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T05:03:03.628303Z","iopub.status.busy":"2024-06-17T05:03:03.627674Z","iopub.status.idle":"2024-06-17T05:03:05.923012Z","shell.execute_reply":"2024-06-17T05:03:05.922103Z","shell.execute_reply.started":"2024-06-17T05:03:03.628272Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["【model】\n"," Qwen2ForSequenceClassification(\n","  (model): Qwen2Model(\n","    (embed_tokens): Embedding(151936, 1024)\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (v_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (o_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (score): ModulesToSaveWrapper(\n","    (original_module): Linear(in_features=1024, out_features=2, bias=False)\n","    (modules_to_save): ModuleDict(\n","      (default): Linear(in_features=1024, out_features=2, bias=False)\n","    )\n","  )\n",")\n","【model.config】\n"," Qwen2Config {\n","  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 2816,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"use_cache\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","【model.config.pad_token_id】 None\n","【预测正确!】Label: human, Pred_Label: human\n","Text: 硬盘接口是硬盘与主机系统间的连接部件，作用是在硬盘缓存和主机内存之间传输数据。不同的硬盘接口决定着硬盘与计算机之间的连接速度，在整个系统中，硬盘接口的优劣直接影响着程序运行快慢和系统性能好坏。\n"]}],"source":["import torch\n","from transformers import DataCollatorWithPadding,AutoTokenizer,AutoModelForSequenceClassification\n","\n","def classify(example,show): #对example进行预测\n","    text=example[\"text\"]\n","    label=example[\"label\"]\n","#     print(\"【example】\",example)\n","    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n","#     print(\"【inputs】\",inputs)\n","    with torch.no_grad(): \n","        output = inference_model(**inputs) \n","        pred = output.logits.argmax(dim=-1).item() \n","    if show:\n","        print(\"【预测{}!】Label: {}, Pred_Label: {}\\nText: {}\".format(\"正确\" if label==pred else \"错误\",id2label[label],id2label[pred],text))\n","    else:\n","        return pred,label\n","\n","# inference_model=model.to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(\"./peft_model_tokenizer\")\n","inference_model = AutoModelForSequenceClassification.from_pretrained(\"./peft_model\").to('cuda') #读取训练好的模型\n","print(\"【model】\\n\",inference_model)\n","print(\"【model.config】\\n\",inference_model.config)\n","print(\"【model.config.pad_token_id】\",inference_model.config.pad_token_id)\n","data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\")\n","\n","id2label = {0: \"human\", 1: \"chatgpt\"}\n","label2id = {\"human\": 0, \"chatgpt\": 1}\n","\n","classify(data_test[0],1) #随便测试一个数据"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T05:03:11.890977Z","iopub.status.busy":"2024-06-17T05:03:11.890612Z","iopub.status.idle":"2024-06-17T05:03:29.582198Z","shell.execute_reply":"2024-06-17T05:03:29.581023Z","shell.execute_reply.started":"2024-06-17T05:03:11.890948Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["【测试集】 Dataset({\n","    features: ['label', 'text'],\n","    num_rows: 500\n","})\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [00:17<00:00, 29.07it/s]"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.982}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from datasets import load_metric\n","from tqdm import tqdm \n","metric=load_metric('accuracy')\n","\n","print(\"【测试集】\",data_test)\n","inference_model.eval() \n","for i,example in enumerate(tqdm(data_test)): \n","    pred, label = classify(example,0)\n","#     print(\"NO.{} 预测{}! Label: {}, Pred_Label: {}\".format(i,\"正确\" if label==pred else \"错误\",id2label[label],id2label[pred]))\n","    metric.add(predictions=pred, references=label)\n","print(metric.compute()) "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
