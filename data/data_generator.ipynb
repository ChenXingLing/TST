{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:28:47.767437Z","iopub.status.busy":"2024-06-17T04:28:47.766791Z","iopub.status.idle":"2024-06-17T04:29:27.967343Z","shell.execute_reply":"2024-06-17T04:29:27.966395Z","shell.execute_reply.started":"2024-06-17T04:28:47.767405Z"},"trusted":true},"outputs":[],"source":["!pip install peft\n","!pip install modelscope"]},{"cell_type":"markdown","metadata":{},"source":["## ã€æ•°æ®å¤„ç†ã€‘"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:03.911282Z","iopub.status.busy":"2024-06-17T04:33:03.910565Z","iopub.status.idle":"2024-06-17T04:33:24.181989Z","shell.execute_reply":"2024-06-17T04:33:24.181054Z","shell.execute_reply.started":"2024-06-17T04:33:03.911252Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-18 19:56:29,975 - modelscope - INFO - PyTorch version 2.2.1 Found.\n","2024-06-18 19:56:29,983 - modelscope - INFO - Loading ast index from C:\\Users\\xingling\\.cache\\modelscope\\ast_indexer\n","2024-06-18 19:56:30,791 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 bf1f8c6a033ab849ecc796d2c086e805 and a total number of 980 components indexed\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n","You can remove this warning by passing 'verification_mode=no_checks' instead.\n","  warnings.warn(\n","c:\\Users\\xingling\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:926: FutureWarning: The repository for HC3-Chinese contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at C:\\Users\\xingling\\.cache\\modelscope\\hub\\datasets\\simpleai\\HC3-Chinese\\master\\meta\\HC3-Chinese.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["ã€æ•°æ®é›†ä¸‹è½½å®Œæˆã€‘\n"]}],"source":["import modelscope\n","from modelscope.msdatasets import MsDataset\n","#ã€ä¸‹è½½æ•°æ®é›†ã€‘\n","HC3=MsDataset.load('simpleai/HC3-Chinese', subset_name='baike', split='train') #è°ƒç”¨HC3æ•°æ®é›†\n","dataset=HC3.to_hf_dataset() #å°†MsDatasetè½¬æ¢æˆhuggingface datasetæ ¼å¼ï¼Œæ–¹ä¾¿åç»­å¤„ç†\n","print(\"ã€æ•°æ®é›†ä¸‹è½½å®Œæˆã€‘\")"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:34.585363Z","iopub.status.busy":"2024-06-17T04:33:34.584724Z","iopub.status.idle":"2024-06-17T04:33:35.083295Z","shell.execute_reply":"2024-06-17T04:33:35.082379Z","shell.execute_reply.started":"2024-06-17T04:33:34.585330Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ç¡¬ç›˜å®‰è£…å°±æ˜¯ä»ç¡¬ç›˜å®‰è£…XPçš„ç³»ç»Ÿï¼Œå¯ä»¥æ˜¯ä¸€èˆ¬çš„ç³»ç»Ÿä¹Ÿå¯ä»¥æ˜¯GHOSTçš„ã€‚é€‚ç”¨äºæ²¡æœ‰æˆ–è€…å…‰é©±æŸåçš„ä¸ªäººç”µè„‘ç”¨æˆ·ã€‚ \\né¦–å…ˆè¦åˆ°ç½‘ä¸Šå»ä¸‹ä¸€ä¸ªç³»ç»Ÿï¼Œè§£å‹åæŠŠæ–‡ä»¶åå­—ä¿®æ”¹ä¸ºxpï¼ˆä¾¿äºåœ¨DOSä¸‹æŸ¥æ‰¾ï¼‰ \\n1ã€GHOSTç³»ç»Ÿæ—¶å€™ï¼Œé‡å¯è¿›å…¥DOSçŠ¶æ€ä¸‹ï¼Œç”¨UBDOCï¼ˆè¶…æ™®DOSï¼‰æˆ–è€…æ˜¯çŸ®äººDOSï¼ˆè¿™ä¸¤ä¸ªè½¯ä»¶å¿…é¡»å…ˆä¸‹è½½å®‰è£…ï¼Œæˆ‘ç”¨è¶…æ™®DOSï¼‰ï¼Œè¿˜æœ‰å°±æ˜¯ä»å…‰ç›˜è¿›å…¥DOSï¼Œå‡è®¾æˆ‘ä»¬çš„ç³»ç»Ÿå®‰è£…ç¨‹åºæ”¾åœ¨Dç›˜äº†ï¼Œ \\nc:\\_è¾“å…¥d:\\å›è½¦ï¼Œæ˜¾ç¤ºDï¼š\\_ç„¶åè¾“å…¥smartdrvå†æ¬¡è¾“å…¥smartdrvåå›è½¦ï¼ˆåŠ è½½ç£ç›˜åŠ é€Ÿç¨‹åºï¼‰ï¼Œç„¶åè¾“å…¥CD XPå›è½¦ï¼Œæ˜¾ç¤ºDï¼š\\XP\\_ç„¶åè¾“å…¥GHOSTå›è½¦ï¼Œè¿›å…¥GHOSTï¼Œåœ¨é‡Œé¢ç”¨é¼ æ ‡å¦‚æœæ²¡æœ‰åŠ è½½å°±ç”¨é”®ç›˜é€‰æ‹©ï¼Œæ‰¾åˆ°from imageç„¶åå›è½¦ä¸€ç›´å›è½¦ï¼ŒçŸ¥é“é€‰æ‹©yeså’Œnoï¼Œé€‰æ‹©yesï¼Œå¾ˆå¿«å°±è£…å¥½äº†ï¼Œå¤§çº¦10åˆ†ï¼Œç«‹åˆ»é‡å¯ã€‚\n","æ¾ç®¡å…‰ç¼†æ˜¯ä¸€ç§å°†å…‰çº¤è£…åœ¨ä¸€ä¸ªæˆ–åˆ†è£…åœ¨å¤šä¸ªç®¡å­é‡Œçš„å…‰ç¼†ã€‚ \\nåœ¨ç¼†èŠ¯ä¸­ä¸å¡«å……æ²¹è†çš„æ¾ç®¡å…‰ç¼†ã€‚åœ¨è¿™ç§å…‰ç¼†ä¸­ç”¨ä¸€ç§æ³¡æ²«çŠ¶çš„çƒ­å¡‘æ€§å¼¹æ€§ä½“æ¥ä»£æ›¿ä¼ ç»Ÿæ¾ç®¡å…‰ç¼†ä¸­çš„æ²¹è†,èµ·åˆ°é˜»æ°´çš„ä½œç”¨ã€‚è¿™ç§å…‰ç¼†å¯ä»¥å‡å°å°ºå¯¸è€Œä¿æŒæœºæ¢°æ€§èƒ½æˆ–è€…ä¿æŒå°ºå¯¸è€Œæé«˜æœºæ¢°æ€§èƒ½ã€‚å–æ¶ˆæ²¹è†å¤§å¤§æ–¹ä¾¿å…‰ç¼†ç«¯å¤´çš„åˆ¶å¤‡å’Œå…‰ç¼†çš„æ¥ç»­,å¹¶æœ‰åˆ©äºç¯å¢ƒä¿æŠ¤ã€‚è¿™ç§å…‰ç¼†æ˜¯ç”±ç‘å…¸çˆ±ç«‹ä¿¡ç½‘ç»œæŠ€æœ¯å…¬å¸å¼€å‘çš„,è¯•åˆ¶äº†æ¶ç©ºã€ç®¡é“å’Œç›´åŸ‹ç”¨å…‰ç¼†,æŠ¥é“äº†è¿™äº›å…‰ç¼†çš„ç»“æ„å’Œæ€§èƒ½è¯•éªŒç»“æœã€‚\n","ç¡¬ç›˜å®‰è£…æ˜¯æŒ‡å°†è½¯ä»¶æˆ–æ“ä½œç³»ç»Ÿå®‰è£…åˆ°ç¡¬ç›˜ä¸Šçš„è¿‡ç¨‹ã€‚ç¡¬ç›˜æ˜¯ç”µè„‘çš„ä¸»å­˜å‚¨å™¨ï¼Œé€šå¸¸ä½¿ç”¨ç¡¬ç›˜æ¥å®‰è£…æ“ä½œç³»ç»Ÿå’Œå…¶ä»–è½¯ä»¶ã€‚åœ¨å®‰è£…ç¡¬ç›˜ä¹‹å‰ï¼Œä½ éœ€è¦å‡†å¤‡å¥½å®‰è£…ä»‹è´¨ï¼ˆé€šå¸¸æ˜¯å…‰ç›˜æˆ– USB é—ªå­˜ç›˜ï¼‰ï¼Œå¹¶æŒ‰ç…§æ“ä½œç³»ç»Ÿçš„å®‰è£…å‘å¯¼è¿›è¡Œæ“ä½œã€‚å®‰è£…å®Œæˆåï¼Œä½ å°±å¯ä»¥ä½¿ç”¨ç¡¬ç›˜ä¸Šçš„è½¯ä»¶äº†ã€‚\n","æ¾ç®¡å…‰ç¼†æ˜¯ä¸€ç§ç±»å‹çš„å…‰çº¤é€šä¿¡çº¿è·¯ï¼Œå®ƒæ˜¯ç”±ä¸€ä¸ªæˆ–å¤šä¸ªå…‰çº¤ç®¡æ„æˆï¼Œå†…éƒ¨åŒ…å«ä¸€æ¡æˆ–å¤šæ¡å…‰çº¤ã€‚æ¾ç®¡å…‰ç¼†é€šå¸¸ç”¨äºåœ¨éš¾ä»¥è¿›è¡Œé“ºè®¾çš„åœ°åŒºè¿›è¡Œé•¿è·ç¦»ä¼ è¾“ï¼Œä¾‹å¦‚æ²³æµã€é«˜é€Ÿå…¬è·¯ã€éš§é“ç­‰ã€‚æ¾ç®¡å…‰ç¼†çš„ä¼˜ç‚¹æ˜¯å¯ä»¥æé«˜çº¿è·¯çš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œå¹¶ä¸”å¯ä»¥æé«˜ä¼ è¾“é€Ÿç‡ã€‚\n"]}],"source":["from datasets import Dataset\n","import numpy as np\n","import torch\n","import json\n","import pickle\n","\n","def dodo(ds,label):\n","    dataset=ds\n","    # dataset=np.array(ds)\n","    # print(dataset.shape)\n","    #æ•°æ®é›†åˆ’åˆ† train:val=8:2\n","    tot=len(dataset)\n","    n_train=int(tot*0.8)\n","    n_valid=tot-n_train\n","    \n","    # data_train=np.array(data_train)\n","    # data_valid=np.array(data_valid)\n","    # print(data_valid)\n","    # print(\"ã€data_train_{}ã€‘\".format(label),data_train.shape)\n","    # print(\"ã€data_valid_{}ã€‘\".format(label),data_valid.shape)\n","    \n","    path=\"./HC3/train.{}\".format(label)\n","    file=open(path, 'w',encoding='utf-8')\n","    print(ds[0].replace('\\n', '\\\\n'))\n","    for i in range(n_train):\n","        file.write(ds[i].replace('\\n', '\\\\n'))\n","        file.write('\\n')\n","\n","    path=\"./HC3/valid.{}\".format(label)\n","    file=open(path, 'w',encoding='utf-8')\n","    print(ds[n_train].replace('\\n', '\\\\n'))\n","    for i in range(n_valid):\n","        file.write(ds[n_train+i].replace('\\n', '\\\\n'))\n","        file.write('\\n')\n","\n","#ã€è°ƒæ•´æ•°æ®é›†æ ¼å¼ã€‘\n","ds0,ds1=[],[]\n","cnt=dataset.num_rows\n","for i in range(cnt):\n","    example=dataset[i]\n","    ds0.append(example[\"human_answers\"][0])\n","    ds1.append(example[\"chatgpt_answers\"][0])\n","\n","dodo(ds0,\"0\")\n","dodo(ds1,\"1\")"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'encode' is an invalid keyword argument for open()","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# è¯»å–æ–‡ä»¶\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./HC3/valid.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      6\u001b[0m     loaded_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_data)  \u001b[38;5;66;03m# è¾“å‡º: {1: 'a', 2: 'b', 3: 'c'}\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","\u001b[1;31mTypeError\u001b[0m: 'encode' is an invalid keyword argument for open()"]}],"source":["import pickle\n"," \n","\n","# è¯»å–æ–‡ä»¶\n","with open('./HC3/valid.1', 'rb',encode='utf-8') as file:\n","    loaded_data = pickle.load(file)\n"," \n","print(loaded_data)  # è¾“å‡º: {1: 'a', 2: 'b', 3: 'c'}"]},{"cell_type":"markdown","metadata":{},"source":["## ã€æ¨¡å‹ã€‘"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:38.397691Z","iopub.status.busy":"2024-06-17T04:33:38.397054Z","iopub.status.idle":"2024-06-17T04:33:55.072749Z","shell.execute_reply":"2024-06-17T04:33:55.071859Z","shell.execute_reply.started":"2024-06-17T04:33:38.397659Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-17 04:33:40.508356: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-17 04:33:40.508488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-17 04:33:40.630987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9bb136cc1954e5db55456ead79c6a72","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8c3ca07dec342b8b78c205bfda30a2c","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37f5fd067c4c40d2b642c6b0322caf4b","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3deb0d591ce4d908007270c3c854fe9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Qwen2TokenizerFast(name_or_path='Qwen/Qwen1.5-0.5B', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03a6ab6ea4574eaeb2013890c58a7275","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc019884950f405dbbe6898a8247cb35","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ã€token_train[0]ã€‘ {'label': 0, 'text': 'ç½‘ç»œèŠ‚ç‚¹æ˜¯æŒ‡ä¸€å°ç”µè„‘æˆ–å…¶ä»–è®¾å¤‡ä¸ä¸€ä¸ªæœ‰ç‹¬ç«‹åœ°å€å’Œå…·æœ‰ä¼ é€æˆ–æ¥æ”¶æ•°æ®åŠŸèƒ½çš„ç½‘ç»œç›¸è¿ã€‚èŠ‚ç‚¹å¯ä»¥æ˜¯å·¥ä½œç«™ã€å®¢æˆ·ã€ç½‘ç»œç”¨æˆ·æˆ–ä¸ªäººè®¡ç®—æœºï¼Œè¿˜å¯ä»¥æ˜¯æœåŠ¡å™¨ã€æ‰“å°æœºå’Œå…¶ä»–ç½‘ç»œè¿æ¥çš„è®¾å¤‡ã€‚æ¯ä¸€ä¸ªå·¥ä½œç«™ï¹‘æœåŠ¡å™¨ã€ç»ˆç«¯è®¾å¤‡ã€ç½‘ç»œè®¾å¤‡ï¼Œå³æ‹¥æœ‰è‡ªå·±å”¯ä¸€ç½‘ç»œåœ°å€çš„è®¾å¤‡éƒ½æ˜¯ç½‘ç»œèŠ‚ç‚¹ã€‚æ•´ä¸ªç½‘ç»œå°±æ˜¯ç”±è¿™è®¸è®¸å¤šå¤šçš„ç½‘ç»œèŠ‚ç‚¹ç»„æˆçš„ï¼ŒæŠŠè®¸å¤šçš„ç½‘ç»œèŠ‚ç‚¹ç”¨é€šä¿¡çº¿è·¯è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€å®šçš„å‡ ä½•å…³ç³»ï¼Œè¿™å°±æ˜¯è®¡ç®—æœºç½‘ç»œæ‹“æ‰‘ã€‚', 'input_ids': [71356, 92374, 104442, 106621, 104145, 105994, 101044, 57218, 46944, 18830, 102024, 46477, 33108, 100629, 112523, 57191, 106585, 20074, 98380, 9370, 71356, 111060, 1773, 92374, 73670, 20412, 114896, 5373, 100017, 5373, 71356, 20002, 57191, 99605, 104564, 3837, 104468, 20412, 89047, 5373, 117648, 105504, 71356, 64064, 9370, 101044, 1773, 104367, 114896, 123930, 239, 89047, 5373, 104992, 101044, 5373, 71356, 101044, 3837, 91676, 103926, 99283, 102157, 71356, 46477, 9370, 101044, 100132, 71356, 92374, 1773, 101908, 71356, 99486, 67071, 43288, 99454, 100694, 42140, 9370, 71356, 92374, 107339, 3837, 99360, 100694, 9370, 71356, 92374, 11622, 104516, 104634, 64064, 99793, 3837, 101894, 102495, 111867, 100145, 3837, 104301, 104564, 71356, 100786, 102498, 1773, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"]}],"source":["from transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer,DataCollatorWithPadding\n","\n","#ã€åŠ è½½åˆ†è¯å™¨ã€‘\n","tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\") #(\"bert-base-cased\")\n","tokenizer.pad_token_id = tokenizer.eos_token_id #Qwenç‰¹æ€§ï¼Œéœ€è¦æŒ‡å®šä¸€ä¸‹pad_token_id\n","print(tokenizer)\n","# print(\"ã€pad_token_idã€‘\",tokenizer.pad_token_id)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"],padding=\"max_length\",truncation=True,max_length=512)\n","\n","token_train=data_train.map(tokenize_function, batched=True)\n","token_val=data_val.map(tokenize_function, batched=True)\n","print(\"ã€token_train[0]ã€‘\",token_train[0])\n","\n","train_dataset = token_train\n","eval_dataset = token_val"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#ä½¿ç”¨BERTæ¨¡å‹\n","# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=5)\n","# print(model)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:33:58.480750Z","iopub.status.busy":"2024-06-17T04:33:58.480388Z","iopub.status.idle":"2024-06-17T04:34:04.025769Z","shell.execute_reply":"2024-06-17T04:34:04.024840Z","shell.execute_reply.started":"2024-06-17T04:33:58.480722Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb10cf5b2a1e4beea1ca0c1b47dcdc85","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7e298cebe41493ca0b9fabece58c4e9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["ã€modelã€‘\n"," Qwen2ForSequenceClassification(\n","  (model): Qwen2Model(\n","    (embed_tokens): Embedding(151936, 1024)\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (score): Linear(in_features=1024, out_features=2, bias=False)\n",")\n","ã€model.configã€‘\n"," Qwen2Config {\n","  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"human\",\n","    \"1\": \"chatgpt\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 2816,\n","  \"label2id\": {\n","    \"chatgpt\": 1,\n","    \"human\": 0\n","  },\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"pad_token_id\": 151643,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"use_cache\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","ã€model.config.pad_token_idã€‘ 151643\n"]}],"source":["#ã€åŠ è½½æ¨¡å‹ã€‘\n","id2label = {0: \"human\", 1: \"chatgpt\"}\n","label2id = {\"human\": 0, \"chatgpt\": 1}\n","#ä½¿ç”¨Qwen1.5æ¨¡å‹\n","model = AutoModelForSequenceClassification.from_pretrained(\"Qwen/Qwen1.5-0.5B\",num_labels=2,id2label=id2label,label2id=label2id)\n","model.config.pad_token_id=model.config.eos_token_id #è¿™é‡Œä¹Ÿè¦æŒ‡å®šä¸€ä¸‹pad_token_idï¼Œä¸ç„¶è®­ç»ƒæ—¶ä¼šæŠ¥é”™ \"ValueError: Cannot handle batch sizes > 1 if no padding token is defined.\"\n","print(\"ã€modelã€‘\\n\",model)\n","print(\"ã€model.configã€‘\\n\",model.config)\n","print(\"ã€model.config.pad_token_idã€‘\",model.config.pad_token_id)"]},{"cell_type":"markdown","metadata":{},"source":["## ã€è®­ç»ƒã€‘"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:36:59.615974Z","iopub.status.busy":"2024-06-17T04:36:59.615082Z","iopub.status.idle":"2024-06-17T04:37:00.187197Z","shell.execute_reply":"2024-06-17T04:37:00.186366Z","shell.execute_reply.started":"2024-06-17T04:36:59.615928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/tmp/ipykernel_34/3640500368.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric=load_metric('accuracy') #è¯„ä¼°æŒ‡æ ‡\n","/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8921a053627c48408b6c423b05c9ee0a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#ã€è®­ç»ƒå‚æ•°ã€‘\n","from datasets import load_metric\n","import numpy as np\n","\n","training_args = TrainingArguments(\n","    output_dir=\"pt_save_pretrained\",\n","    evaluation_strategy=\"epoch\", #æ¯è·‘å®Œä¸€ä¸ªepochè¾“å‡ºä¸€ä¸‹æµ‹è¯•ä¿¡æ¯\n","    num_train_epochs=2,\n","    per_device_train_batch_size=4, # ä¸€å…±è¦è·‘ len(dataset)/batch_size * epoch ä¸ªstep\n","                                  # [æ¨¡å‹=Qwen1.5-0.5B, batch_size=4]ï¼šå®Œå…¨å¾®è°ƒæ˜¾å­˜13.3GBï¼ŒLoRAå¾®è°ƒæ˜¾å­˜8.7GB\n","#     gradient_accumulation_steps=2,\n","    #     load_best_model_at_end=True,\n","    save_strategy=\"no\",  #å…³é—­è‡ªåŠ¨ä¿å­˜æ¨¡å‹ï¼ˆKaggleä¸Šç£ç›˜ç©ºé—´ä¸å¤ªå¤Ÿï¼‰\n","#     save_total_limit=1, #ä¿å­˜æ£€æŸ¥ç‚¹æ•°é‡çš„é™åˆ¶\n",")\n","\n","metric=load_metric('accuracy') #è¯„ä¼°æŒ‡æ ‡\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","def get_trainer(model): \n","    return  Trainer( \n","        model=model, \n","        args=training_args, \n","        tokenizer=tokenizer,\n","        train_dataset=train_dataset, \n","        eval_dataset=eval_dataset, \n","        compute_metrics=compute_metrics,\n","        data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\"), #ç»™æ•°æ®æ·»åŠ paddingå¼„æˆbatch\n","    ) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#ã€å®Œå…¨å¾®è°ƒã€‘\n","print(\"ã€å¼€å§‹è®­ç»ƒã€‘\")\n","trainer=get_trainer(model)\n","trainer.train()\n","\n","tokenizer.save_pretrained(\"./full_model_tokenizer\") \n","model.save_pretrained(\"./full_model\")\n","\n","#Kaggleæ³¨æ„ï¼š\n","#æ¯æ¬¡è®­ç»ƒä¹‹årestartä»¥é‡Šæ”¾æ˜¾å­˜ï¼\n","#factoryä¹Ÿresetä¸€ä¸‹ï¼Œä¸ç„¶ç£ç›˜ç©ºé—´ä¼šçˆ†ï¼"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T04:37:06.150074Z","iopub.status.busy":"2024-06-17T04:37:06.149373Z","iopub.status.idle":"2024-06-17T05:01:11.990221Z","shell.execute_reply":"2024-06-17T05:01:11.989119Z","shell.execute_reply.started":"2024-06-17T04:37:06.150041Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PEFTå‚æ•°é‡ï¼š\n","trainable params: 1,181,696 || all params: 465,171,456 || trainable%: 0.2540\n","ã€å¼€å§‹è®­ç»ƒã€‘\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240617_043743-e2nrmyuv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">pt_save_pretrained</a></strong> to <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/chenxingling/huggingface' target=\"_blank\">https://wandb.ai/chenxingling/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv' target=\"_blank\">https://wandb.ai/chenxingling/huggingface/runs/e2nrmyuv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 23:08, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.102500</td>\n","      <td>0.113912</td>\n","      <td>0.986000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.052600</td>\n","      <td>0.107569</td>\n","      <td>0.986000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["#ã€PEFT-LoRAå¾®è°ƒã€‘\n","from peft import LoraConfig, get_peft_model\n","\n","peft_config = LoraConfig(\n","    task_type=\"SEQ_CLS\", #ä»»åŠ¡ç±»å‹ï¼šåˆ†ç±» \n","    target_modules=[\"q_proh\",\"k_proj\",\"v_proj\",\"o_proj\"],  # è¿™ä¸ªä¸åŒçš„æ¨¡å‹éœ€è¦è®¾ç½®ä¸åŒçš„å‚æ•°ï¼Œä¸»è¦çœ‹æ¨¡å‹ä¸­çš„attentionå±‚\n","    inference_mode=False, # å…³é—­æ¨ç†æ¨¡å¼ (å³å¼€å¯è®­ç»ƒæ¨¡å¼)\n","    r=8, # Lora ç§©\n","    lora_alpha=16, # Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†\n","    lora_dropout=0.1 # Dropout æ¯”ä¾‹\n",")\n","\n","peft_model = get_peft_model(model, peft_config) # åŠ è½½loraå‚æ•°peftæ¡†æ¶\n","\n","print('PEFTå‚æ•°é‡ï¼š') \n","peft_model.print_trainable_parameters() \n","\n","print(\"ã€å¼€å§‹è®­ç»ƒã€‘\")\n","peft_trainer=get_trainer(peft_model)\n","peft_trainer.train()\n","\n","tokenizer.save_pretrained(\"./peft_model_tokenizer\") \n","peft_model.save_pretrained(\"./peft_model\")"]},{"cell_type":"markdown","metadata":{},"source":["## ã€æµ‹è¯•ã€‘"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T05:03:03.628303Z","iopub.status.busy":"2024-06-17T05:03:03.627674Z","iopub.status.idle":"2024-06-17T05:03:05.923012Z","shell.execute_reply":"2024-06-17T05:03:05.922103Z","shell.execute_reply.started":"2024-06-17T05:03:03.628272Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["ã€modelã€‘\n"," Qwen2ForSequenceClassification(\n","  (model): Qwen2Model(\n","    (embed_tokens): Embedding(151936, 1024)\n","    (layers): ModuleList(\n","      (0-23): 24 x Qwen2DecoderLayer(\n","        (self_attn): Qwen2SdpaAttention(\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (k_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (v_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (o_proj): lora.Linear(\n","            (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.1, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=1024, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","          )\n","          (rotary_emb): Qwen2RotaryEmbedding()\n","        )\n","        (mlp): Qwen2MLP(\n","          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n","          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): Qwen2RMSNorm()\n","        (post_attention_layernorm): Qwen2RMSNorm()\n","      )\n","    )\n","    (norm): Qwen2RMSNorm()\n","  )\n","  (score): ModulesToSaveWrapper(\n","    (original_module): Linear(in_features=1024, out_features=2, bias=False)\n","    (modules_to_save): ModuleDict(\n","      (default): Linear(in_features=1024, out_features=2, bias=False)\n","    )\n","  )\n",")\n","ã€model.configã€‘\n"," Qwen2Config {\n","  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 2816,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"use_cache\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","ã€model.config.pad_token_idã€‘ None\n","ã€é¢„æµ‹æ­£ç¡®!ã€‘Label: human, Pred_Label: human\n","Text: ç¡¬ç›˜æ¥å£æ˜¯ç¡¬ç›˜ä¸ä¸»æœºç³»ç»Ÿé—´çš„è¿æ¥éƒ¨ä»¶ï¼Œä½œç”¨æ˜¯åœ¨ç¡¬ç›˜ç¼“å­˜å’Œä¸»æœºå†…å­˜ä¹‹é—´ä¼ è¾“æ•°æ®ã€‚ä¸åŒçš„ç¡¬ç›˜æ¥å£å†³å®šç€ç¡¬ç›˜ä¸è®¡ç®—æœºä¹‹é—´çš„è¿æ¥é€Ÿåº¦ï¼Œåœ¨æ•´ä¸ªç³»ç»Ÿä¸­ï¼Œç¡¬ç›˜æ¥å£çš„ä¼˜åŠ£ç›´æ¥å½±å“ç€ç¨‹åºè¿è¡Œå¿«æ…¢å’Œç³»ç»Ÿæ€§èƒ½å¥½åã€‚\n"]}],"source":["import torch\n","from transformers import DataCollatorWithPadding,AutoTokenizer,AutoModelForSequenceClassification\n","\n","def classify(example,show): #å¯¹exampleè¿›è¡Œé¢„æµ‹\n","    text=example[\"text\"]\n","    label=example[\"label\"]\n","#     print(\"ã€exampleã€‘\",example)\n","    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n","#     print(\"ã€inputsã€‘\",inputs)\n","    with torch.no_grad(): \n","        output = inference_model(**inputs) \n","        pred = output.logits.argmax(dim=-1).item() \n","    if show:\n","        print(\"ã€é¢„æµ‹{}!ã€‘Label: {}, Pred_Label: {}\\nText: {}\".format(\"æ­£ç¡®\" if label==pred else \"é”™è¯¯\",id2label[label],id2label[pred],text))\n","    else:\n","        return pred,label\n","\n","# inference_model=model.to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(\"./peft_model_tokenizer\")\n","inference_model = AutoModelForSequenceClassification.from_pretrained(\"./peft_model\").to('cuda') #è¯»å–è®­ç»ƒå¥½çš„æ¨¡å‹\n","print(\"ã€modelã€‘\\n\",inference_model)\n","print(\"ã€model.configã€‘\\n\",inference_model.config)\n","print(\"ã€model.config.pad_token_idã€‘\",inference_model.config.pad_token_id)\n","data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True,return_tensors=\"pt\")\n","\n","id2label = {0: \"human\", 1: \"chatgpt\"}\n","label2id = {\"human\": 0, \"chatgpt\": 1}\n","\n","classify(data_test[0],1) #éšä¾¿æµ‹è¯•ä¸€ä¸ªæ•°æ®"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T05:03:11.890977Z","iopub.status.busy":"2024-06-17T05:03:11.890612Z","iopub.status.idle":"2024-06-17T05:03:29.582198Z","shell.execute_reply":"2024-06-17T05:03:29.581023Z","shell.execute_reply.started":"2024-06-17T05:03:11.890948Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["ã€æµ‹è¯•é›†ã€‘ Dataset({\n","    features: ['label', 'text'],\n","    num_rows: 500\n","})\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:17<00:00, 29.07it/s]"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.982}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from datasets import load_metric\n","from tqdm import tqdm \n","metric=load_metric('accuracy')\n","\n","print(\"ã€æµ‹è¯•é›†ã€‘\",data_test)\n","inference_model.eval() \n","for i,example in enumerate(tqdm(data_test)): \n","    pred, label = classify(example,0)\n","#     print(\"NO.{} é¢„æµ‹{}! Label: {}, Pred_Label: {}\".format(i,\"æ­£ç¡®\" if label==pred else \"é”™è¯¯\",id2label[label],id2label[pred]))\n","    metric.add(predictions=pred, references=label)\n","print(metric.compute()) "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
